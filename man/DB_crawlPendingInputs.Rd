% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/DB_crawlPendingInputs.R
\name{DB_crawlPendingInputs}
\alias{DB_crawlPendingInputs}
\title{Process a Batch of Pending URLs: Scraping and Storage}
\usage{
DB_crawlPendingInputs(
  db_con,
  batch_inputs,
  tab_queue = "tab_queue",
  tab_crawl = "tab_crawl",
  get_func = GETscrapling,
  success_func = craw_crawSuccess,
  status_func = craw_crawStatus,
  ...
)
}
\arguments{
\item{db_con}{A valid \code{DBIConnection} to the SQLite database.}

\item{batch_inputs}{Character vector of URLs to crawl (already marked in_progress).}

\item{tab_crawl}{Character(1). Name of the crawl results table (default: "tab_crawl").}

\item{get_func}{Function(URLs, proxies, ...) returning a list of responses.}

\item{success_func}{Function(response) → logical indicating success.}

\item{status_func}{Function(response) → integer status code.}

\item{...}{Additional args passed to \code{get_func}.}

\item{proxies_fn}{Function() → vector/list of proxies for \code{get_func}.}
}
\value{
A tibble with columns:
\itemize{
\item URL (input URL),
\item HTML_TEXT (body),
\item resp_status,
\item crawl_success,
\item crawled_at (timestamp).
}
}
\description{
Fetches a batch of in-progress URLs and scrapes each one using the provided
\code{get_func}. Evaluates success and status with \code{success_func} and \code{status_func},
then atomically appends the results to the crawl table.
}
